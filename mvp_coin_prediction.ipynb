{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REST API\n",
    "\n",
    "import requests\n",
    "import pandas as pd # 1분봉 조회하기\n",
    "import numpy as np\n",
    "import pyupbit\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_splitted_data_generater(df, window_size):\n",
    "    \n",
    "    x_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    for i in range(len(df) - window_size):\n",
    "        x_list.append(df.iloc[i:i+window_size, : -1])\n",
    "        y_list.append(df.iloc[i + window_size, -1])\n",
    "        \n",
    "    \n",
    "    x_list = np.array(x_list)\n",
    "    y_list = np.array(y_list)\n",
    "        \n",
    "    return x_list, y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. Load data\n",
    "url = \"https://api.upbit.com/v1/market/all\"\n",
    "\n",
    "resp = requests.get(url)\n",
    "data = resp.json()\n",
    "\n",
    "\n",
    "df = pyupbit.get_ohlcv(\"KRW-BTC\", \"minute1\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. data normalization\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df.iloc[:, 0:4] = scaler.fit_transform(df.iloc[:, 0:4])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train, test data\n",
    "SPLIT = int(0.7*len(df)) \n",
    "train_df = df[:SPLIT]\n",
    "test_df = df[SPLIT:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Prepare X, y according to prediction window.\n",
    "\n",
    "window_size = 10 # predicting close price using data from 10 previous minutes\n",
    "x_train, y_train = window_splitted_data_generater(train_df, window_size)\n",
    "x_test, y_test = window_splitted_data_generater(test_df, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class CoinLSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=1, hidden_size = 50, num_layers = 1, batch_first= True)\n",
    "        self.linear = nn.Linear(50,1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x)\n",
    "        x = self.linear(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(x_batch, y_batch, optimizer, loss_fn, model):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # forward pass\n",
    "    y_pred = model(x_batch)\n",
    "    \n",
    "    # calculate loss of the batch\n",
    "    loss = loss_fn(y_pred, y_batch)\n",
    "    \n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    \n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create custom dataset \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'DataLoader'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m      4\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m----> 5\u001b[0m train_data_loader \u001b[38;5;241m=\u001b[39m  \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m(data\u001b[38;5;241m.\u001b[39mTensorDataset(x_train, y_train), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      6\u001b[0m val_data_loader \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mDataLoader(data\u001b[38;5;241m.\u001b[39mTensorDataset(x_test, y_test), batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[0;32m      8\u001b[0m tr_loss_history \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'DataLoader'"
     ]
    }
   ],
   "source": [
    "# assgin model, optimizer, loss_fn, data_loader\n",
    "model = CoinLSTM()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_fn = nn.MSELoss()\n",
    "train_data_loader =  data.DataLoader(data.TensorDataset(x_train, y_train), shuffle=True, batch_size=8)\n",
    "val_data_loader = data.DataLoader(data.TensorDataset(x_test, y_test), batch_size = 8)\n",
    "\n",
    "tr_loss_history = []\n",
    "val_loss_history = []\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Important to set training mode\n",
    "    losses = []\n",
    "    \n",
    "    for X_batch, y_batch in train_data_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        loss = train_step(X_batch, y_batch)\n",
    "        tr_loss_history.append(loss)\n",
    "    \n",
    "    # Add validation step after each epoch\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Uses loader to fetch one mini-batch for validation\n",
    "        for x_val, y_val in val_data_loader:\n",
    "            # Again, sends data to same device as model\n",
    "            x_val = x_val.to(device)\n",
    "            y_val = y_val.to(device)\n",
    "            \n",
    "            model.eval()\n",
    "\n",
    "            yhat = model(x_val)\n",
    "\n",
    "            val_loss = loss_fn(y_val, yhat)\n",
    "            val_loss_history.append(val_loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
